# ğŸ¥ Web Tutorial Script: Scrapy Crash Course with VS Code

---

## ğŸ”´ INTRO

**Narration:**

> "Hey everyone! In this tutorial, Iâ€™ll show you how to go from zero to scraping with **Scrapy** using **VS Code**. Weâ€™ll install Scrapy, set up a project, write a few spiders, and export the data in different formats."

---

## 1ï¸âƒ£ Installing Scrapy in a Virtual Environment

**Narration:**

> "Letâ€™s start by setting up a virtual environment and installing Scrapy."

**Terminal Commands:**

```bash
# Create and activate a virtual environment
python -m venv scrapy_env

# Windows\scrapy_env\Scripts\activate
# macOS/Linux
source scrapy_env/bin/activate

# Install Scrapy
pip install scrapy
```

**VS Code Tip:**
Open VS Code inside the project folder:

```bash
code .
```

---

## 2ï¸âƒ£ Creating a Scrapy Project

**Narration:**

> "Now letâ€™s create our first Scrapy project."

**Terminal Commands:**

```bash
scrapy startproject quotes_scraper
cd quotes_scraper
```

**Project Structure:**

```
quotes_scraper/
â”œâ”€â”€ scrapy.cfg
â””â”€â”€ quotes_scraper/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ items.py
    â”œâ”€â”€ middlewares.py
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ settings.py
    â””â”€â”€ spiders/
        â””â”€â”€ __init__.py
```

---

## 3ï¸âƒ£ Creating a Basic Spider

**Narration:**

> "Letâ€™s create a spider that scrapes quotes from a demo site."

**File:** `quotes_scraper/spiders/quotes_spider.py`

```python
import scrapy

class QuotesSpider(scrapy.Spider):
    name = "quotes"
    start_urls = ['http://quotes.toscrape.com']

    def parse(self, response):
        for quote in response.css("div.quote"):
            yield {
                'text': quote.css("span.text::text").get(),
                'author': quote.css("small.author::text").get(),
                'tags': quote.css("div.tags a.tag::text").getall(),
            }
```

---

## 4ï¸âƒ£ Running the Spider

**Narration:**

> "Now, letâ€™s run the spider and export the data to a JSON file."

**Terminal Command:**

```bash
scrapy crawl quotes -o quotes.json
```

**Result:** Show `quotes.json` in VS Code.

---

## 5ï¸âƒ£ Following Links to Scrape Author Details

**Narration:**

> "Letâ€™s enhance our spider to follow links and grab author bios."

**Update Spider:**

```python
def parse(self, response):
    for quote in response.css("div.quote"):
        author_url = quote.css("a::attr(href)").get()
        yield response.follow(author_url, self.parse_author)

def parse_author(self, response):
    yield {
        'name': response.css("h3.author-title::text").get().strip(),
        'birthdate': response.css("span.author-born-date::text").get(),
        'bio': response.css("div.author-description::text").get().strip()
    }
```

---

## 6ï¸âƒ£ Using XPath Selectors (Alternate Example)

**Narration:**

> â€œYou can also use XPath instead of CSS for scraping.â€

**Example:**

```python
def parse(self, response):
    for quote in response.xpath("//div[@class='quote']"):
        yield {
            'text': quote.xpath("span[@class='text']/text()").get(),
            'author': quote.xpath("span/small[@class='author']/text()").get(),
            'tags': quote.xpath("div[@class='tags']/a[@class='tag']/text()").getall()
        }
```

---

## 7ï¸âƒ£ Exporting Data to CSV

**Narration:**

> "You can also export to CSV or XML with one command."

**Command:**

```bash
scrapy crawl quotes -o quotes.csv
```

---

## 8ï¸âƒ£ Using Scrapy Shell for Testing Selectors

**Narration:**

> "Use the Scrapy shell to test selectors interactively."

**Commands:**

```bash
scrapy shell http://quotes.toscrape.com
```

Then try:

```python
response.css("span.text::text").getall()
response.xpath("//span[@class='text']/text()").getall()
```

---

## 9ï¸âƒ£ Bonus: Pagination

**Narration:**

> â€œLetâ€™s scrape all pages by following the â€˜Nextâ€™ button.â€

**Update Spider:**

```python
def parse(self, response):
    for quote in response.css("div.quote"):
        yield {
            'text': quote.css("span.text::text").get(),
            'author': quote.css("small.author::text").get(),
            'tags': quote.css("div.tags a.tag::text").getall(),
        }

    next_page = response.css("li.next a::attr(href)").get()
    if next_page:
        yield response.follow(next_page, self.parse)
```

---

## ğŸ”š Wrap Up

**Narration:**

> â€œAnd thatâ€™s a quick crash course on Scrapy with VS Code! You learned how to install Scrapy, set up a project, write spiders, follow links, and export data in multiple formats.â€

> â€œIf this helped you, give it a like and subscribe. Check the description for the full code and extra resources.â€
